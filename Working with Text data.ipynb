{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Text Data - NLP BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:16.752230Z",
     "start_time": "2019-09-10T06:25:16.747245Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for text and sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications of these algorithms includes:\n",
    "- Document Classification and time series classification, such as identifying the topic of an article or the author of the book.\n",
    "- Timeseries comparisons, such as estimating how closely related two documents or two stock tickers are,\n",
    "- Sequence to sequence learning, such as decoding an English sentence to French,\n",
    "- Sentiment analysis, such as classifying the sentiment of tweets or movie reviews as positive or negative,\n",
    "- Timeseries forecasting, such as predicting the future weather at a certain location, given recent weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all other neural networks, deep learning models don't take as input raw text:\n",
    "- They only work with numeric tensors.\n",
    "- Vectorizing text is the process of transforming text into numeric tensors.\n",
    "- This can be done in multiple ways:\n",
    "    - Segment text into words, and transform each word into a vector\n",
    "    - Segment text into characters, and transforms each character into a vector.\n",
    "    - Extract n-grams of words or characters, and transform each n-gram into a vector.\n",
    "    - N-grams are overlapping groups of multiple consecutive words or characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different units into which we can break down text(words, characters, or n-grams) are called **tokens** and the process is called **tokenization**.<br><br>\n",
    "\n",
    "Ways to associate a vector with a token:\n",
    "- One hot encoding\n",
    "- Token embedding(word embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word level one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:17.132061Z",
     "start_time": "2019-09-10T06:25:17.006552Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homwork.']    # Initial data: one entry per sample(In this example, a sample is a sentence, but it could be an entire document)\n",
    "\n",
    "token_index = {}                                                    # Builds an index of all tokens in the data\n",
    "for sample in samples:\n",
    "    for word in sample.split():                                     # Tokenizes the samples via the split method. In real life, you'd also strip punctuation and special characters fromt he samples.\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1                # Assigns a unique index to each unique word. Note that you don't attributr index o to anything.\n",
    "            \n",
    "max_length = 10                                                     # Vectorizes the samples, You'll only consider the first max_length words in each sample.\n",
    "\n",
    "results = np.zeros(shape=(len(samples),\n",
    "                          max_length,\n",
    "                          max(token_index.values()) + 1))           # This is where you store the results.\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:17.144029Z",
     "start_time": "2019-09-10T06:25:17.134056Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homwork.']\n",
    "characters = string.printable                                               # All printable ASCII characters\n",
    "token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras for word-level one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:20.232475Z",
     "start_time": "2019-09-10T06:25:17.146025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homwork.']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)                                  # Creates a tokenizer, configured to only take into account the 1000 ost common words.\n",
    "tokenizer.fit_on_texts(samples)                                        # Builds the word index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)                      # Turns strings into lists of integer indices\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')    # You could also directly et the one-hot binary representation. Vectorization modes other than one-hot encoding are supported by this tokenizer\n",
    "\n",
    "word_index = tokenizer.word_index                                      # How you can recover the word index that was computed\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word level one-hot encoding with hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:20.240454Z",
     "start_time": "2019-09-10T06:25:20.234470Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homwork.']\n",
    "\n",
    "dimensionality = 1000                                              # Stores the words as vectors of size 1000. If you have close to 1000 words(or more), you'll see many hash collisions, which will decrease the accuracy of this encoding method.\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality                   # Hashes the word into a random integer index between 0 and 1000\n",
    "        results[i, j, index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Vectors obtained through OHE| Vectors obtained using word embeddings|\n",
    "| ------------- | -------------------|\n",
    "| Binary and sparse(almost made of zero) | dense word vectors|\n",
    "| Very high dimensionality | low dimension floating-point vectors |\n",
    "| Leads to vectors that are 20000 dimensional or greater | 256 dimensional, 512 dimensional, when dealing with large vocabularies |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning word embedding with embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simplest way to associate a dense vector with a word is to choose the vector at random.\n",
    "- Problem with this is that resulting embedding space has no structure.\n",
    "- It's difficult for a deep neural network to make sense of such a noisy, unstructured embedding space.\n",
    "- Geometric relationships between word vectors should reflect the semantic relationship between words.\n",
    "- Its thus reasonable to learn, a new embedding space with every new task.\n",
    "- Backpropagation makes this easy, and Keras makes it even easier.\n",
    "- Its about learning the weights of a layer, the Embedding Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:21.566801Z",
     "start_time": "2019-09-10T06:25:20.242447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mrshu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(1000, 64)  # takes at least two arguments: the number of possible tokens(here, 1000: 1 + maximum word index) and the dimensionality of the embedding(here, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word index ------------> Embedding Layer --------------> Corresponding word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading IMDB data for use with an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:25:26.381931Z",
     "start_time": "2019-09-10T06:25:21.568740Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000                                   # number of words to consider as features\n",
    "maxlen = 20                                            # Cuts off the text after this number of words(among the max_features most common words)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
    "    num_words=max_features)                            # Loads the data as list of integers \n",
    "\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) # Turns the lists of integers into a 2D interger tensor of shape(samples, maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Embedding layer and classifier on the IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T06:29:40.442637Z",
     "start_time": "2019-09-10T06:29:31.592564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.6676 - acc: 0.6182 - val_loss: 0.6167 - val_acc: 0.6928\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.5415 - acc: 0.7488 - val_loss: 0.5276 - val_acc: 0.7324\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.4626 - acc: 0.7865 - val_loss: 0.5027 - val_acc: 0.7424\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.4222 - acc: 0.8096 - val_loss: 0.4961 - val_acc: 0.7494\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.3935 - acc: 0.8254 - val_loss: 0.4968 - val_acc: 0.7540\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.3699 - acc: 0.8382 - val_loss: 0.4998 - val_acc: 0.7530\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.3491 - acc: 0.8496 - val_loss: 0.5043 - val_acc: 0.7522\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.3289 - acc: 0.8606 - val_loss: 0.5123 - val_acc: 0.7512\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.3108 - acc: 0.8705 - val_loss: 0.5178 - val_acc: 0.7478\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.2929 - acc: 0.8800 - val_loss: 0.5278 - val_acc: 0.7452\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pretrained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various precomputed databases of word embeddings that you can download and use in Keras Embedding layer.\n",
    "- Word2vec is one of them.\n",
    "- Another popular one is called Global vectors fro Word Representation based on factorizing a matrix of word co-occurence statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T07:36:00.436541Z",
     "start_time": "2019-09-10T07:33:17.597488Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = 'C:/Users/mrshu/Downloads/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='latin1')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the data\n",
    "\n",
    "- Vectorize and prepare a training and validation split.\n",
    "- We will restrict the training data to the first 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T08:03:45.290822Z",
     "start_time": "2019-09-10T08:03:38.380263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88584 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100                                               # Cut off reviews after 100 words\n",
    "training_samples = 200                                     # Train on 200 samples\n",
    "validation_samples = 10000                                 # Validates on 10,000 samples\n",
    "max_words = 10000                                          # Considers only the top 10000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])                          # Splits the data into a training set and a validation set, but first shuffles the data\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the GloVe word-embeddings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T09:46:18.334451Z",
     "start_time": "2019-09-10T09:46:04.493369Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = 'C:/Users/mrshu/Downloads/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the GloVe word embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T10:01:06.817454Z",
     "start_time": "2019-09-10T10:01:06.764575Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector           # words not found in the embedding index will be all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T10:21:48.014342Z",
     "start_time": "2019-09-10T10:21:45.959763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained word embeddings into the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T11:02:31.042681Z",
     "start_time": "2019-09-10T11:02:28.765140Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].translate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T11:17:28.999501Z",
     "start_time": "2019-09-10T11:17:17.151148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 3s 14ms/step - loss: 1.6777 - acc: 0.5000 - val_loss: 0.7195 - val_acc: 0.5261\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.8162 - acc: 0.6150 - val_loss: 0.7149 - val_acc: 0.5214\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3258 - acc: 0.9350 - val_loss: 0.7091 - val_acc: 0.5490\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2164 - acc: 0.9450 - val_loss: 0.7670 - val_acc: 0.5248\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1633 - acc: 0.9750 - val_loss: 1.2619 - val_acc: 0.5078\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1670 - acc: 0.9600 - val_loss: 0.7680 - val_acc: 0.5356\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0516 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.5449\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1133 - acc: 0.9750 - val_loss: 0.9916 - val_acc: 0.5151\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.8112 - val_acc: 0.5385\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.8443 - val_acc: 0.5360\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val))\n",
    "\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T11:39:00.922408Z",
     "start_time": "2019-09-10T11:39:00.666958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='validation_acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the same model without pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:04:06.594397Z",
     "start_time": "2019-09-10T12:04:00.173740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.6895 - acc: 0.4950 - val_loss: 0.6938 - val_acc: 0.5221\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4796 - acc: 0.9850 - val_loss: 0.7033 - val_acc: 0.5257\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2549 - acc: 0.9850 - val_loss: 0.7071 - val_acc: 0.5293\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1074 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.5309\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0500 - acc: 1.0000 - val_loss: 0.7326 - val_acc: 0.5315\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 0.5328\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.5320\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5335\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.5353\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.5341\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                      epochs=10,\n",
    "                      batch_size=32,\n",
    "                      validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the data of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:37:41.774429Z",
     "start_time": "2019-09-10T12:34:49.065645Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf-8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T12:52:02.746757Z",
     "start_time": "2019-09-10T12:51:59.790159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8547371725416183, 0.52904]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Till now:\n",
    "    - Turned raw text into something a neural networks can process.\n",
    "    - Used the Embedding layer in a Keras models to learn task specific token embeddings.\n",
    "    - Used pretrained word embeddings to get an extra boost on small natural language processing problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
